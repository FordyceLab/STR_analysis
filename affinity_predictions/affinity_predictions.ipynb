{
 "cells": [
  {
   "cell_type": "raw",
   "id": "0fe3206d-0b74-40a9-b9ba-1a7a499fc932",
   "metadata": {},
   "source": [
    "TF-DNA affinity-prediction tools\n",
    "Copyright (C) 2022  Connor A. Horton\n",
    "\n",
    "This program is free software: you can redistribute it and/or modify\n",
    "it under the terms of the GNU General Public License as published by\n",
    "the Free Software Foundation, either version 3 of the License, or\n",
    "(at your option) any later version.\n",
    "\n",
    "This program is distributed in the hope that it will be useful,\n",
    "but WITHOUT ANY WARRANTY; without even the implied warranty of\n",
    "MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n",
    "GNU General Public License for more details.\n",
    "\n",
    "You should have received a copy of the GNU General Public License\n",
    "along with this program.  If not, see <https://www.gnu.org/licenses/>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cabb10e9-6f7c-41e3-90ce-140d511b8fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from Bio.Seq import Seq\n",
    "\n",
    "def ddG(Kd, ref_Kd, R=1.9872036e-3, T=295):\n",
    "    '''\n",
    "    compute ∆∆G in kcal/mol relative to reference Kd\n",
    "    '''\n",
    "    return R*T*np.log(Kd/ref_Kd)\n",
    "\n",
    "kBT = 0.593"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6c5462b-603e-4e06-a9b3-03507c00043b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in library of sequences to predict binding on\n",
    "lib1_seqs = pd.read_csv('library1_names_sequences.csv')\n",
    "lib2_seqs = pd.read_csv('library2_names_sequences.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dff8aace-61a9-4d82-a175-f4308a1c8a2c",
   "metadata": {},
   "source": [
    "# PSAM prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e164cb59-f371-4f2e-8ae5-b30586b4dd1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_matrix(seq):\n",
    "    '''\n",
    "    helper function to generate one-hot encoded sequence matrix\n",
    "    '''\n",
    "    seq_matrix = np.zeros((4, len(seq)))\n",
    "    for j in range(len(seq)):\n",
    "        if seq[j] == 'A':\n",
    "            seq_matrix[0,j] = 1\n",
    "        elif seq[j] == 'C':\n",
    "            seq_matrix[1,j] = 1\n",
    "        elif seq[j] == 'G':\n",
    "            seq_matrix[2,j] = 1\n",
    "        elif seq[j] == 'T':\n",
    "            seq_matrix[3,j] = 1\n",
    "    return seq_matrix\n",
    "\n",
    "def get_PSAM_score(sequence, score_matrix):\n",
    "    '''\n",
    "    calculate PSAM score (a relative binding affinity) given a sequence and PSAM\n",
    "    '''\n",
    "    score = 0\n",
    "    score_len = score_matrix.shape[0]\n",
    "    # iterate through all positions of the sequence with a sliding window\n",
    "    for j in range(len(sequence) - score_len + 1):\n",
    "        seq_matrix = generate_matrix(sequence[j:j+score_len])\n",
    "        diagonal = np.diagonal(np.matmul(score_matrix,seq_matrix))\n",
    "        score += np.prod(diagonal)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b7f8a24e-0ee4-460d-aaae-40bf5a39d401",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in PSAM from Maerkl & Quake, Science, 2007.\n",
    "MAX_PSAM = np.array(pd.read_csv('MAX_PSAM_MaerklQuake2007.csv',index_col=0)).T\n",
    "# compute predicted binding\n",
    "lib1_seqs['MAX_PSAM_pred'] = lib1_seqs['Sequence'].apply(lambda x: ddG(1,get_PSAM_score(x,MAX_PSAM)))\n",
    "lib2_seqs['MAX_PSAM_pred'] = lib2_seqs['Sequence'].apply(lambda x: ddG(1,get_PSAM_score(x,MAX_PSAM)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34c2cc80-c640-4147-a99a-875da768f2b3",
   "metadata": {},
   "source": [
    "# Sliding Z-score prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1f103eea-1d7a-4385-9ef8-88ab53d1d7f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sliding_Z(sequence, Z_dict, k=8):\n",
    "    # compute Z score for each window of length k in sequence\n",
    "    sliding_Z_score = [Z_dict[sequence[i:i+k]] for i in range(len(sequence)-k+1)]\n",
    "    # return the sum of Z scores\n",
    "    return np.sum(sliding_Z_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ec205179-2d93-4c78-b397-58cc9529b7fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import Z scores\n",
    "all_Zscores = pd.read_csv('Zscores_MAX_Pho4.csv').set_index('8mer')\n",
    "# make dictionary from Z scores\n",
    "MAX_Zscores = all_Zscores['MAX'].to_dict()\n",
    "# add reverse complements to dictionary for completeness\n",
    "MAX_Zscores.update({str(Seq(k).reverse_complement()): v for k,v in MAX_Zscores.items()})\n",
    "# predicting binding\n",
    "lib1_seqs['MAX_slidingZ_pred'] = lib1_seqs['Sequence'].apply(lambda x: sliding_Z(x,MAX_Zscores))\n",
    "lib2_seqs['MAX_slidingZ_pred'] = lib2_seqs['Sequence'].apply(lambda x: sliding_Z(x,MAX_Zscores))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87b6acf3-5844-4436-b735-e994f9c00735",
   "metadata": {},
   "source": [
    "# Partition function prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b3f8869a-6878-40a2-9228-2f140fb75310",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_gibbs_calibrated(E_array, slope, kBT=0.593):\n",
    "    partition = [np.exp(-E/kBT) for E in E_array]\n",
    "    return -slope*kBT*np.log(np.sum(partition))\n",
    "\n",
    "def compute_enthalpy_calibrated(E_array, slope, kBT=0.593):\n",
    "    enthalpy_array = [E*np.exp(-E/kBT) for E in E_array]\n",
    "    enthalpy_array /= np.sum([np.exp(-E/kBT) for E in E_array])\n",
    "    return slope*np.sum(enthalpy_array)\n",
    "\n",
    "def compute_entropy_calibrated(E_array, slope, kBT=0.593):\n",
    "    p_array = compute_p_array(E_array)\n",
    "    entropy_array = [p*np.log(p) for p in p_array]\n",
    "    return -slope*np.sum(entropy_array)\n",
    "\n",
    "def gibbs_wrapper(sequence, E_dict, slope):\n",
    "    return compute_gibbs_calibrated([E_dict[sequence[i:i+8]] for i in range(len(sequence)-7)],slope)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "37a1137d-ee5b-4c51-8bea-5597fd087559",
   "metadata": {},
   "outputs": [],
   "source": [
    "# see figure 2 in main text for calculation\n",
    "slope_Pho4 = 3.00\n",
    "slope_MAX = 4.03\n",
    "# we are going to normalize our predictions to sequences with a motif surrounded by random flanks. they are listed below\n",
    "ref_oligos_lib1 = [14,18,22]\n",
    "ref_oligos_lib2 = [0,5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b73c2388-9aa3-4ae6-a2a4-744754336c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in uPBM data from Badis et al. Science 2009.\n",
    "MAX_rep1 = pd.read_csv('uPBM_data/MAX_8mers_rep1.txt',\n",
    "                       delimiter='\\t', names=['8mer', 'RC', 'intensity', 'Escore'], usecols=np.arange(4))\n",
    "MAX_rep1['E'] = -np.log(MAX_rep1['intensity'])\n",
    "MAX_rep1['E'] -= np.mean(MAX_rep1['E'])\n",
    "\n",
    "MAX_rep2 = pd.read_csv('uPBM_data/MAX_8mers_rep2.txt',\n",
    "                       delimiter='\\t', names=['8mer', 'RC', 'intensity', 'Escore'], usecols=np.arange(4))\n",
    "MAX_rep2['E'] = -np.log(MAX_rep2['intensity'])\n",
    "MAX_rep2['E'] -= np.mean(MAX_rep2['E'])\n",
    "\n",
    "# convert E scores to dictionary for compatibility with analysis\n",
    "MAX_E_dict = {k:v for k,v in zip(MAX_rep1['8mer'], np.mean([MAX_rep1['E'], MAX_rep2['E']],axis=0))}\n",
    "MAX_E_dict.update({k:v for k,v in zip(MAX_rep1['RC'], np.mean([MAX_rep1['E'], MAX_rep2['E']],axis=0))})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b0a6c0f8-918f-4b36-a730-349499d96f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict binding\n",
    "lib1_seqs['MAX_statmech_pred'] = lib1_seqs['Sequence'].apply(lambda x: gibbs_wrapper(x,MAX_E_dict,slope_MAX))\n",
    "# normalize to reference sequence\n",
    "lib1_seqs['MAX_statmech_pred'] -= lib1_seqs.loc[ref_oligos_lib1,'MAX_statmech_pred'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0cdc7331-c9ac-41df-a988-18e24e23dbea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict binding\n",
    "lib2_seqs['MAX_statmech_pred'] = lib2_seqs['Sequence'].apply(lambda x: gibbs_wrapper(x,MAX_E_dict,slope_MAX))\n",
    "# normalize to reference sequence\n",
    "lib2_seqs['MAX_statmech_pred'] -= lib2_seqs.loc[ref_oligos_lib2,'MAX_statmech_pred'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ff9cf5-a46b-4cd1-ac9a-f6720a691531",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6a3fcb8a-295e-41e8-bca7-f2a9f0cecbde",
   "metadata": {},
   "source": [
    "#### save predictions to file in csv format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0fa97820-4ff2-4f1a-84f2-813ba069a1ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "lib1_seqs.to_csv('lib1_bindingpredictions.csv', index=False)\n",
    "lib2_seqs.to_csv('lib2_bindingpredictions.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e9976b7-2336-4909-93b4-e14c559c7a29",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
